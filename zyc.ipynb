{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import os,csv\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 45\n",
    "\n",
    "# Other\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process (No need to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('.'):\n",
    "    for item in dirs:\n",
    "        if (item[0]!='.'):\n",
    "            try:\n",
    "                os.remove(os.path.join(item,'.DS_Store'))\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir('extracted_images/')\n",
    "for subfolder in folders:\n",
    "    subfolder_here = os.listdir(os.path.join('extracted_images',subfolder))     \n",
    "    j = -1\n",
    "    for image in subfolder_here:\n",
    "        j+=1\n",
    "        os.rename(os.path.join('extracted_images',subfolder,image), os.path.join('extracted_images',subfolder,subfolder+'_'+str(j)+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir('mathsymbol')\n",
    "except FileExistsError:\n",
    "    pass\n",
    "folders = os.listdir('extracted_images')\n",
    "with open('msb.csv', mode='w') as msb:\n",
    "    msb_writer = csv.writer(msb, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    msb_writer.writerow(['Filename', 'Class Label'])\n",
    "    i = -1\n",
    "    for subfolder in folders:\n",
    "        i += 1\n",
    "        subfolder_here = os.listdir(os.path.join('extracted_images',subfolder))\n",
    "        for image in subfolder_here:\n",
    "            msb_writer.writerow([image,str(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in folders:\n",
    "    subfolder_here = os.listdir(os.path.join('extracted_images',subfolder))     \n",
    "    for image in subfolder_here:\n",
    "        shutil.copy(os.path.join('extracted_images',subfolder,image), os.path.join('mathsymbol',image) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    return int(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f6 = open('msb.csv', encoding=\"utf-8\")\n",
    "reader6 = list(csv.reader(f6))\n",
    "f6.close()\n",
    "sorted(reader6[1:],key=get_label,reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image_paths = sorted(glob.glob('mathsymbol/*.jpg'))\n",
    "for i in (1,2000,18000,43284):\n",
    "    im_path = image_paths[i]\n",
    "    print(im_path)\n",
    "    im = Image.open(im_path)\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickdrawDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Quickdraw images\"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(csv_path)\n",
    "        self.img_dir = img_dir\n",
    "        self.img_names = df['Filename'].values\n",
    "        self.y = df['Class Label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution Train [ 117   46    8   24  103   98   49   14   12   56   10    2    3  185\n",
      "  247   22 1383   22  171 1847   12  506  134  157  155   96    6   32\n",
      "  114   35    3   27  160   77   75  146   45  810   19  743   21  141\n",
      "  814   45   41]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('sample_data/sample_train.csv')\n",
    "print('Class distribution Train', np.bincount(df_train['Class Label'].values))\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "\n",
    "train_dataset = QuickdrawDataset(csv_path='sample_data/sample_train.csv',\n",
    "                                 img_dir='mathsymbol/',\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=128, #### CHANGE IF YOU LIKE 128*0.9\n",
    "                          shuffle=True,\n",
    "                          num_workers=4)\n",
    "\n",
    "\n",
    "valid_dataset = QuickdrawDataset(csv_path='sample_data/sample_valid.csv',\n",
    "                                 img_dir='mathsymbol/',\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4)\n",
    "\n",
    "test_dataset = QuickdrawDataset(csv_path='sample_data/sample_test.csv',\n",
    "                                img_dir='mathsymbol/',\n",
    "                                transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=128,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Batch index: 0 | Batch size: 128\n",
      "break minibatch for-loop\n",
      "Epoch: 2 | Batch index: 0 | Batch size: 128\n",
      "break minibatch for-loop\n"
     ]
    }
   ],
   "source": [
    "#just check if data are loaded correctly\n",
    "torch.manual_seed(0)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        \n",
    "        print('Epoch:', epoch+1, end='')\n",
    "        print(' | Batch index:', batch_idx, end='')\n",
    "        print(' | Batch size:', y.size()[0])\n",
    "        \n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        \n",
    "        print('break minibatch for-loop')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### NO NEED TO CHANGE THIS CELL\n",
    "###############################\n",
    "\n",
    "def compute_epoch_loss(model, data_loader):\n",
    "    model.eval()\n",
    "    curr_loss, num_examples = 0., 0\n",
    "    with torch.no_grad():\n",
    "        for features, targets in data_loader:\n",
    "            features = features.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "            logits, probas = model(features)\n",
    "            loss = F.cross_entropy(logits, targets, reduction='sum')\n",
    "            num_examples += targets.size(0)\n",
    "            curr_loss += loss\n",
    "\n",
    "        curr_loss = curr_loss / num_examples\n",
    "        return curr_loss\n",
    "\n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### NO NEED TO CHANGE THIS CELL\n",
    "###############################\n",
    "\n",
    "def train(model, train_loader, test_loader):\n",
    "\n",
    "    minibatch_cost, epoch_cost = [], []\n",
    "    start_time = time.time()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        model.train()\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "            features = features.to(DEVICE)\n",
    "            targets = targets.to(DEVICE)\n",
    "\n",
    "            ### FORWARD AND BACK PROP\n",
    "            logits, probas = model(features)\n",
    "            cost = F.cross_entropy(logits, targets)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            cost.backward()\n",
    "            minibatch_cost.append(cost)\n",
    "\n",
    "            ### UPDATE MODEL PARAMETERS\n",
    "            optimizer.step()\n",
    "\n",
    "            ### LOGGING\n",
    "            if not batch_idx % 150:\n",
    "                print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                       %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                         len(train_loader), cost))\n",
    "\n",
    "    \n",
    "        with torch.set_grad_enabled(False): # save memory during inference\n",
    "            print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "                  epoch+1, NUM_EPOCHS, \n",
    "                  compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "            \n",
    "            cost = compute_epoch_loss(model, train_loader)\n",
    "            epoch_cost.append(cost)\n",
    "\n",
    "        print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "    print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))\n",
    "\n",
    "    print('Total Time: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "    return minibatch_cost, epoch_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "class ConvNet3(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=NUM_CLASSES):\n",
    "        super(ConvNet3, self).__init__()\n",
    "        \n",
    "        #### YOUR CODE\n",
    "        self.conv0 = nn.Conv2d(1, 3, kernel_size=5, stride=1,padding=12)\n",
    "        self.pool0  = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv1 =  nn.Conv2d(3, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5,stride=1,padding=2)\n",
    "        self.bn2   = nn.BatchNorm2d(192)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3   = nn.BatchNorm2d(384)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(384, 256, kernel_size=5,stride=1,padding=2)\n",
    "        self.bn4   = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=5,stride=1,padding=2)\n",
    "        self.bn5   = nn.BatchNorm2d(256)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=(2,2),stride=2,padding=0)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.linear1 = nn.Linear(256,4096)\n",
    "        self.bnnl1   = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.linear2 = nn.Linear(4096,4096)\n",
    "        self.bnnl2   = nn.BatchNorm1d(4096)\n",
    "        \n",
    "        self.linear3 = nn.Linear(4096, num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #### YOUR CODE\n",
    "        out = self.conv0(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool0(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.conv1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool1(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.dropout(out, p=0.2, training=self.training)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool2(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = F.dropout(out, p=0.2, training=self.training)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool3(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.bn4(out)\n",
    "        out = F.dropout(out, p=0.2, training=self.training)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool4(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.conv5(out)\n",
    "        out = self.bn5(out)\n",
    "        out = F.dropout(out, p=0.2, training=self.training)\n",
    "        out = self.relu(out)\n",
    "        out = self.pool5(out)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.linear1(out.view(out.size(0),256))\n",
    "        out = self.bnnl1(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        #print(out.size())\n",
    "        \n",
    "        out = self.linear2(out)\n",
    "        out = self.bnnl2(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, p=0.5, training=self.training)\n",
    "        #print(out.size())\n",
    "        \n",
    "        logits = self.linear3(out)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model3 = ConvNet3(NUM_CLASSES)\n",
    "model3.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model3.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "minibatch_cost, epoch_cost = train(model3, train_loader, test_loader)\n",
    "\n",
    "\n",
    "plt.plot(range(len(minibatch_cost)), minibatch_cost)\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Minibatch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(epoch_cost)), epoch_cost)\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
